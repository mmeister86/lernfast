# Interactive Learning System - Dokumentation

## √úbersicht

Das neue Interactive Learning System ersetzt klassische Flashcards durch einen modernen 3-Phasen-Lern-Workflow mit Vercel AI SDK v5.

## üéØ 3-Phasen-Workflow

### 1. Dialog-Phase (üí¨)

**Ziel**: Wissensabfrage durch KI-gesteuertes Gespr√§ch

- **Technologie**: Vercel AI SDK `streamUI` mit `gpt-4o-mini`
- **Interaktion**: Live-Chat zwischen User und KI
- **Tool Call**: `assessKnowledge` - Bewertet Vorwissen und bestimmt Level
- **Score**: 0-100 (basierend auf Konfidenz des Assessments)
- **Transition**: Automatisch zu Story-Phase nach erfolgreichem Assessment

### 2. Story-Phase (üìñ)

**Ziel**: Narratives Lernen mit Visualisierungen

- **Technologie**: Vorab-generierte Kapitel mit Recharts-Visualisierungen
- **Content**: 3-5 Kapitel (je nach Micro-Dose/Deep-Dive)
- **Visualisierungen**:
  - Timeline (LineChart)
  - Comparison (BarChart)
  - Process (Horizontal BarChart)
  - Concept-Map (PieChart)
- **Navigation**: Vor/Zur√ºck zwischen Kapiteln
- **Transition**: Manuell zum Quiz nach letztem Kapitel

### 3. Quiz-Phase (üéØ)

**Ziel**: Wissenstest mit adaptivem Schwierigkeitsgrad

- **Technologie**: Vorab-generierte Multiple-Choice Fragen
- **Content**: 5-7 Fragen (je nach Micro-Dose/Deep-Dive)
- **Format**: 4 Antwortoptionen, sofortige Erkl√§rung
- **Score**: 0-100 (% richtige Antworten)
- **Adaptive Difficulty**: Tool Call passt Schwierigkeit basierend auf Performance an
- **Transition**: Manuell zu Completed nach letzter Frage

### 4. Completed (üéâ)

**Ziel**: Erfolgs-Screen mit Quiz-Score

- **Anzeige**:
  - Gesamt-Score (entspricht quiz_score 1:1)
  - Quiz-Statistiken (richtige Antworten, Zeit)
  - Dialog-Einsch√§tzung (informativ, nicht gewertet)
- **Actions**: Zur√ºck zum Dashboard oder neue Lesson starten

## üóÑÔ∏è Datenbank-Schema

### Neue Tabelle: `lesson_score`

```sql
CREATE TABLE lesson_score (
  id UUID PRIMARY KEY,
  lesson_id UUID REFERENCES lesson(id),
  user_id TEXT REFERENCES "user"(id),

  -- Phase-Scores (0-100)
  dialog_score INT DEFAULT 0,
  story_engagement_score INT DEFAULT 0,
  quiz_score INT DEFAULT 0,

  -- Auto-berechnet via Trigger (total_score = quiz_score)
  total_score INT DEFAULT 0,

  -- Metadaten
  correct_answers INT,
  total_questions INT,
  time_spent_seconds INT,

  created_at TIMESTAMP,
  updated_at TIMESTAMP,

  UNIQUE(lesson_id, user_id)
);
```

### Erweiterte Tabelle: `lesson`

```sql
ALTER TABLE lesson
  ADD COLUMN current_phase TEXT DEFAULT 'dialog'
    CHECK (current_phase IN ('dialog', 'story', 'quiz', 'completed'));
```

### Erweiterte Tabelle: `flashcard`

```sql
ALTER TABLE flashcard
  ADD COLUMN learning_content JSONB DEFAULT '{}'::jsonb,
  ADD COLUMN phase TEXT CHECK (phase IN ('dialog', 'story', 'quiz')),
  ADD COLUMN order_index INT DEFAULT 0;
```

**learning_content Struktur:**

```typescript
{
  story?: {
    chapterTitle: string;
    narrative: string;
    keyPoints: string[];
    visualizations: [{
      type: "timeline" | "comparison" | "process" | "concept-map";
      title: string;
      chartData: any[]; // Recharts-kompatibel
    }];
  },
  quiz?: {
    question: string;
    options: string[]; // 4 Optionen
    correctAnswer: number; // Index 0-3
    difficulty: "easy" | "medium" | "hard";
    explanation: string;
  }
}
```

## üöÄ Content-Generierung Pipeline

### Neues System (Interactive Learning)

```
User erstellt Lesson
    ‚Üì
API: POST /api/trigger-lesson
    ‚Üì
1. Research (gpt-4.1-mini / o4-mini-deep-research)
    ‚Üì
2. Story Generation (gpt-4.1-mini)
   - 3-5 Kapitel mit Visualisierungen
   - Speicherung in flashcard (phase='story')
    ‚Üì
3. Quiz Generation (gpt-4.1-mini)
   - 5-7 Fragen mit Erkl√§rungen
   - Speicherung in flashcard (phase='quiz')
    ‚Üì
Lesson Status: completed, current_phase: dialog
    ‚Üì
User startet Lesson
    ‚Üì
DIALOG-PHASE (Live-Generierung via streamUI)
    ‚Üì
STORY-PHASE (Gespeicherte Kapitel)
    ‚Üì
QUIZ-PHASE (Gespeicherte Fragen)
    ‚Üì
COMPLETION (Score-Anzeige)
```

### Model-Auswahl (aus ENV-Variablen)

| Phase         | Micro-Dose     | Deep-Dive               | ENV-Variable                                         |
| ------------- | -------------- | ----------------------- | ---------------------------------------------------- |
| Dialog (Live) | `gpt-4o-mini`  | `gpt-4o-mini`           | `OPENAI_SELECTION_MODEL`                             |
| Research      | `gpt-4.1-mini` | `o4-mini-deep-research` | `OPENAI_MICRO_DOSE_MODEL` / `OPENAI_DEEP_DIVE_MODEL` |
| Story         | `gpt-4.1-mini` | `gpt-4.1-mini`          | `OPENAI_STRUCTURE_MODEL`                             |
| Quiz          | `gpt-4.1-mini` | `gpt-4.1-mini`          | `OPENAI_STRUCTURE_MODEL`                             |

## üìÅ Dateistruktur

```
app/
‚îú‚îÄ‚îÄ lesson/[id]/
‚îÇ   ‚îú‚îÄ‚îÄ page.tsx                     # ‚úÖ Hybrid Viewer (alt + neu)
‚îÇ   ‚îî‚îÄ‚îÄ actions.ts                   # ‚úÖ Server Actions mit streamUI
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ trigger-lesson/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ route.ts                 # ‚úÖ Neue Interactive Learning Pipeline
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ route-old-flashcards.ts.backup  # Backup der alten Version
‚îÇ   ‚îî‚îÄ‚îÄ lesson/
‚îÇ       ‚îú‚îÄ‚îÄ update-score/route.ts    # ‚úÖ Score-Update API
‚îÇ       ‚îî‚îÄ‚îÄ update-phase/route.ts    # ‚úÖ Phase-Transition API

components/
‚îî‚îÄ‚îÄ learning/                        # ‚úÖ Neue Interactive Learning Components
    ‚îú‚îÄ‚îÄ dialog-phase.tsx            # Dialog-UI mit Chat-Interface
    ‚îú‚îÄ‚îÄ story-phase.tsx             # Story-UI mit Kapitel-Navigation
    ‚îú‚îÄ‚îÄ quiz-phase.tsx              # Quiz-UI mit adaptivem Assessment
    ‚îú‚îÄ‚îÄ learning-progress.tsx       # Phase-Progress Indicator
    ‚îú‚îÄ‚îÄ completion-screen.tsx       # Erfolgs-Screen mit Score
    ‚îú‚îÄ‚îÄ modern-visualization.tsx    # Recharts-Charts (Timeline, Comparison, etc.)
    ‚îî‚îÄ‚îÄ README.md                   # Component-Dokumentation

lib/
‚îú‚îÄ‚îÄ lesson.types.ts                 # ‚úÖ Erweitert um Interactive Learning Types
‚îî‚îÄ‚îÄ score.types.ts                  # ‚úÖ Neu: Score-Management Types
```

## üîß API-Endpunkte

### POST `/api/trigger-lesson`

Erstellt neue Interactive Learning Lesson

**Input:**

```typescript
{
  topic: string;
  refinedTopic?: string;
  lessonType: "micro_dose" | "deep_dive";
}
```

**Output:**

```typescript
{
  success: true;
  lessonId: string;
  status: "completed";
  message: string;
}
```

### POST `/api/lesson/update-score`

Aktualisiert Score einer Lesson

**Input:**

```typescript
{
  lessonId: string;
  scoreData: {
    dialog_score?: number;
    story_engagement_score?: number;
    quiz_score?: number;
    correct_answers?: number;
    total_questions?: number;
    time_spent_seconds?: number;
  };
}
```

### POST `/api/lesson/update-phase`

Wechselt zwischen Phasen

**Input:**

```typescript
{
  lessonId: string;
  phase: "dialog" | "story" | "quiz" | "completed";
}
```

## üé® UI-Komponenten

### DialogPhase

**Props:**

- `lessonId: string`
- `userId: string`
- `topic: string`

**Features:**

- Live-Chat mit KI
- Streaming UI Responses
- Automatisches Knowledge-Assessment
- Typing-Indicator Animation

### StoryPhase

**Props:**

- `chapters: StoryChapter[]`
- `lessonId: string`

**Features:**

- Kapitel-Navigation (Vor/Zur√ºck)
- Interaktive Recharts-Visualisierungen
- Key Learnings pro Kapitel
- Kapitel-√úbersicht
- Smooth Page-Transitions (Framer Motion)

### QuizPhase

**Props:**

- `questions: QuizQuestion[]`
- `lessonId: string`
- `userId: string`

**Features:**

- Multiple-Choice (4 Optionen)
- Sofortige Erkl√§rungen
- Echtzeit-Score-Tracking
- Farbcodierte Schwierigkeitsgrade
- Fragen-√úbersicht
- Adaptive Difficulty (via Tool Calls)

### ModernVisualization

**Props:**

- `type: "timeline" | "comparison" | "process" | "concept-map"`
- `data: { title: string; chartData: any[] }`

**Chart-Typen:**

1. **Timeline**: LineChart f√ºr chronologische Entwicklungen
2. **Comparison**: BarChart f√ºr Vergleiche
3. **Process**: Horizontal BarChart f√ºr Prozess-Schritte
4. **Concept-Map**: PieChart f√ºr Konzept-Verteilungen

## üîÑ Backward Compatibility

Das System unterst√ºtzt BEIDE Formate:

1. **Neue Lessons** (`current_phase` vorhanden):

   - Interactive Learning mit Dialog ‚Üí Story ‚Üí Quiz

2. **Alte Lessons** (`current_phase` = null):
   - Fallback auf klassischen FlashcardViewer
   - Keine Breaking Changes f√ºr bestehende Inhalte

**Erkennung in Lesson Page:**

```typescript
const isInteractiveLearning = !!lessonWithFlashcards.current_phase;
```

## üß™ Testing

### Manuelle Tests

1. **Neue Lesson erstellen**:

   - Homepage ‚Üí Thema eingeben ‚Üí "Lernen starten"
   - Pr√ºfen: Lesson hat `current_phase='dialog'`

2. **Dialog-Phase testen**:

   - Fragen beantworten
   - Warten auf `assessKnowledge` Tool Call
   - Pr√ºfen: Transition zu Story-Phase

3. **Story-Phase testen**:

   - Kapitel durchklicken
   - Visualisierungen pr√ºfen
   - "Zum Quiz!" Button ‚Üí Transition

4. **Quiz-Phase testen**:

   - Fragen beantworten
   - Score-Tracking pr√ºfen
   - "Quiz beenden!" ‚Üí Completion Screen

5. **Dashboard pr√ºfen**:
   - Score-Anzeige in LessonCard
   - Fortschrittsbalken (Gradient)
   - Phase-Badges

### Zu pr√ºfende Szenarien

- [ ] Dialog-Assessment mit verschiedenen Wissens-Leveln (beginner, intermediate, advanced)
- [ ] Story-Visualisierungen in verschiedenen Browsern (Chrome, Safari, Firefox)
- [ ] Quiz adaptive Difficulty (3 richtig in Folge ‚Üí schwerer, 3 falsch ‚Üí leichter)
- [ ] Score-Berechnung korrekt (20/20/60 Gewichtung)
- [ ] Phase-Transitions funktionieren
- [ ] Alte Lessons funktionieren noch (Fallback auf FlashcardViewer)

## üêõ Bekannte Limitationen

1. **Dialog-Content wird nicht persistiert**:

   - Conversation-History nur im Client-State
   - Bei Page-Reload geht Chat-History verloren
   - **Fix f√ºr sp√§ter**: Speichere Messages in DB

2. **Story-Engagement-Score nicht implementiert**:

   - Aktuell immer 0
   - **Fix f√ºr sp√§ter**: Track Kapitel-Completion + Lesezeit

3. **Adaptive Difficulty im Quiz**:

   - Tool Call `adaptDifficulty` wird noch nicht vom Quiz-UI aufgerufen
   - **Fix f√ºr sp√§ter**: Implementiere Streak-Tracking im QuizPhase-Component

4. **Page-Reload bei Phase-Transitions**:
   - Aktuell `window.location.reload()` nach Phase-Update
   - **Fix f√ºr sp√§ter**: Nutze Next.js Router mit revalidation

## üìä Performance-Metriken

### Content-Generierung (Micro-Dose)

| Phase             | Tokens (Input) | Tokens (Output) | Kosten (ca.) |
| ----------------- | -------------- | --------------- | ------------ |
| Research          | ~500           | ~800            | $0.001       |
| Story (3 Kapitel) | ~1000          | ~1200           | $0.002       |
| Quiz (5 Fragen)   | ~800           | ~600            | $0.001       |
| **Total**         | ~2300          | ~2600           | **$0.004**   |

### Content-Generierung (Deep-Dive)

| Phase              | Tokens (Input) | Tokens (Output) | Kosten (ca.) |
| ------------------ | -------------- | --------------- | ------------ |
| Research (o4-mini) | ~800           | ~1500           | $0.005       |
| Story (5 Kapitel)  | ~1500          | ~2000           | $0.003       |
| Quiz (7 Fragen)    | ~1200          | ~1000           | $0.002       |
| **Total**          | ~3500          | ~4500           | **$0.010**   |

### Live-Generierung (Dialog-Phase)

- **Pro Message**: ~200-400 Tokens
- **Durchschnittlich 3-5 Messages**: ~1000-2000 Tokens total
- **Kosten**: $0.001-$0.002 pro Dialog

## üîê Sicherheit

- **RLS**: `lesson_score` Tabelle hat Row Level Security
- **Ownership**: Alle API-Routes pr√ºfen User-Berechtigung
- **Session**: Better-Auth Session-Validierung in allen Server Actions
- **Input-Validierung**: Zod-Schemas f√ºr alle Tool-Parameter

## üöÄ Deployment-Schritte

1. **Datenbank-Migration ausf√ºhren**:

   ```bash
   # Migration ist bereits in Supabase durchgef√ºhrt ‚úÖ
   ```

2. **Dependencies installieren**:

   ```bash
   pnpm install  # Vercel AI SDK v5 + Recharts + Framer Motion
   ```

3. **ENV-Variablen pr√ºfen**:

   ```bash
   # Stelle sicher dass diese gesetzt sind:
   OPENAI_API_KEY=sk-...
   OPENAI_SELECTION_MODEL=gpt-4o-mini
   OPENAI_MICRO_DOSE_MODEL=gpt-4.1-mini
   OPENAI_DEEP_DIVE_MODEL=o4-mini-deep-research
   OPENAI_STRUCTURE_MODEL=gpt-4.1-mini
   ```

4. **Build & Deploy**:
   ```bash
   pnpm build
   # Deploy zu Vercel
   ```

## üìù N√§chste Schritte (Optional)

### Verbesserungen

1. **Dialog-History Persistenz**:

   - Speichere Chat-Messages in DB
   - Erm√∂gliche "Zur√ºck zum Dialog" auch nach Story-Start

2. **Story-Engagement Tracking**:

   - Track welche Kapitel gelesen wurden
   - Messe Lesezeit pro Kapitel
   - Berechne Engagement-Score (0-100)

3. **Erweiterte Adaptive Difficulty**:

   - Implementiere Streak-Tracking im Quiz
   - Rufe `adaptDifficulty` Tool Call bei 3er-Streaks auf
   - Zeige Difficulty-√Ñnderung in UI

4. **Smooth Phase-Transitions**:

   - Nutze Next.js Router + Server Actions statt Page-Reload
   - Bessere UX mit Loading-States

5. **Social Features**:
   - Teile Scores mit Freunden
   - Leaderboards
   - Achievements f√ºr hohe Scores

## üé® Design-System

Alle Components folgen Neobrutalismus-Prinzipien:

- **Border-Radius**: 15px (NICHT rounded-none!)
- **Borders**: 4px schwarz
- **Shadows**: 4px/4px Offset
- **Retro-Farben**:
  - Peach (#FFC667) - Dialog-Phase
  - Pink (#FB7DA8) - Story-Highlights
  - Purple (#662CB7) - Quiz-Header
  - Teal (#00D9BE) - Success/Completion
  - Coral (#FC5A46) - Errors/Incorrect
- **Typography**:
  - Headings: font-extrabold (weight 800)
  - Body: font-medium (weight 500)

## üìû Support

Bei Fragen oder Problemen:

1. Check `CLAUDE.md` f√ºr Projekt-Kontext
2. Check diese Datei f√ºr Interactive Learning Details
3. Check Component-READMEs in `components/learning/`

**Status**: ‚úÖ Vollst√§ndig implementiert (2025-10-17)
**Version**: 1.2.1 - Interactive Learning MVP + Robuste Visualisierungen

---

## üîß Robuste Visualisierungs-Validierung (V1.2.1 - 2025-10-17)

### Problem gel√∂st

Process-Visualisierungen renderten ein graues Overlay statt echte Charts, weil:
1. LLM generierte teilweise leere/invalide `chartData` Arrays
2. Keine Validierung der LLM-Outputs vor dem Speichern
3. ProcessChart Component hatte kein Error-Handling

### L√∂sung: 3-stufige Validierung + Fallback-Daten

#### 1. Verbesserter LLM-Prompt (OpenAI Best Practices)

**Strukturierter Prompt nach Cookbook-Guidelines:**
- Klare Beispiele f√ºr jeden Visualisierungstyp (timeline, comparison, process, concept-map)
- Explizite Regeln: MINDESTENS 3-6 Datenpunkte, NIEMALS leere Arrays
- Konkrete Format-Vorgaben: `{ name: "String", value: Number }`

#### 2. 3-stufige Server-Side Validierung

**Implementierung in `app/lesson/[id]/actions.tsx`:**

```typescript
// Validierung 1: Ist chartData ein Array?
if (!Array.isArray(finalChartData)) { finalChartData = []; }

// Validierung 2: Hat chartData mindestens 3 Eintr√§ge?
if (finalChartData.length < 3) {
  // Automatischer Fallback mit sinnvollen Test-Daten
}

// Validierung 3: Struktur-Check f√ºr jeden Datenpunkt
validatedChartData.map((item) => {
  if (!item.name || typeof item.name !== "string") { ... }
  if (typeof item.value !== "number") { ... }
})
```

**Fallback-Daten f√ºr jeden Typ:**
- `timeline`: 4 Phasen (25, 55, 80, 100)
- `comparison`: 4 Optionen (75, 60, 85, 70)
- `process`: 4 Schritte (100, 80, 60, 30)
- `concept-map`: 4 Teile (40, 30, 20, 10)

#### 3. ProcessChart Component Verbesserungen

**Features in `components/learning/modern-visualization.tsx`:**
- Early-Return bei leeren Daten
- `domain={[0, 100]}` f√ºr X-Achse (fixiert Werte-Range)
- `width={180}` f√ºr Y-Achse (mehr Platz f√ºr lange Schritt-Namen)
- Debug-Logging f√ºr Daten-Inspektion

#### 4. Debugging-Support

**Console-Logging auf mehreren Ebenen:**
1. `üìä createChapter Tool Called:` ‚Üí Zeigt LLM-Output
2. `‚ö†Ô∏è LLM returned invalid chartData` ‚Üí Fallback wird aktiviert
3. `‚úÖ Final validated chartData:` ‚Üí Zeigt finale Daten
4. `‚úÖ Chapter saved successfully` ‚Üí Speicherung erfolgreich
5. `üé® ModernVisualization rendering successfully` ‚Üí Chart wird gerendert

#### Impact

**Vorher:**
- ‚ùå Graues Overlay bei invaliden Daten
- ‚ùå Keine Fehlerdiagnose m√∂glich

**Nachher:**
- ‚úÖ LLM wird strukturiert zu validen Daten angeleitet
- ‚úÖ Automatischer Fallback bei LLM-Fehler
- ‚úÖ Jeder Datenpunkt strukturell validiert
- ‚úÖ ProcessChart rendert korrekt mit horizontalen Balken
- ‚úÖ Umfassendes Logging f√ºr schnelles Debugging

#### Ge√§nderte Dateien

- `app/lesson/[id]/actions.tsx` (System-Prompt + Validierung)
- `components/learning/modern-visualization.tsx` (Error-Handling + ProcessChart Fix)
- `INTERACTIVE-LEARNING.md` (Diese Dokumentation)

#### Verifikation

‚úÖ LLM-Prompt nach OpenAI Best Practices strukturiert
‚úÖ 3-stufige Validierung implementiert
‚úÖ Fallback-Daten f√ºr alle 4 Visualisierungstypen
‚úÖ ProcessChart Component robustifiziert
‚úÖ Umfassendes Debug-Logging
‚úÖ Dokumentation aktualisiert

---

## üéØ Dialog-Phase Limit (V1.1 - 2025-10-16)

### Problem gel√∂st

Die Dialog-Phase dauerte zu lange, da das LLM den User in ein langes Gespr√§ch verwickelte ohne klare Begrenzung.

### L√∂sung: Maximal 5 User-Antworten

#### Dialog-Phase Flow

```
User antwortet
  ‚Üì
Counter erh√∂ht (1-5)
  ‚Üì
if (Counter < 5) ‚Üí continueDialog() ‚Üí KI fragt weiter
if (Counter === 5) ‚Üí forceAssessment() ‚Üí Automatisches Assessment
  ‚Üì
Phase ‚Üí "story"
```

#### UI/UX Improvements

**Progress-Anzeige im Header:**

- Badge: `{userAnswerCount}/5` mit farbcodierung
- Progress-Bar mit dynamischer Breite
- Text: "Beantworte noch X Fragen"

**Farbcodierung der Progress-Bar:**

- Gr√ºn (3-5 verbleibend): `bg-[#00D9BE]`
- Gelb (2 verbleibend): `bg-[#FFC667]`
- Orange (1 verbleibend): `bg-[#FC5A46]`

**Warnungen:**

- Bei 4. Frage: "‚ö†Ô∏è Das ist deine letzte Frage!"
- Bei 5. Frage: Input deaktiviert + "Dialog abgeschlossen ‚úì"

#### Server-Side Implementation

**`continueDialog()` angepasst:**

```typescript
export async function continueDialog(
  // ... standard params ...
  currentAnswerCount?: number, // NEU: Aktuelle Frage-Nummer (1-5)
  maxAnswers?: number // NEU: Max 5
): Promise<ReactNode>;
```

System-Prompt Versch√§rfung:

```
STRIKTE REGEL - MAXIMAL 5 FRAGEN:
- Der Nutzer hat bisher X von 5 Fragen beantwortet
- [Bei Frage 4] "DIES IST DIE LETZTE FRAGE!"
- [Nach Frage 3] "Du kannst jetzt assessKnowledge Tool verwenden"
- EINE Frage pro Message - Keine Zusammenfassungen
- Sei pr√§gnant - Stelle die Frage DIREKT!
```

**`forceAssessment()` (NEU):**

```typescript
export async function forceAssessment(
  lessonId: string,
  userId: string,
  conversationHistory: Array<{ role; content }>,
  topic: string
): Promise<ReactNode>;
```

- Wird nach 5 User-Antworten automatisch aufgerufen
- Analysiert komplette Conversation-History
- Erstellt finales Assessment OHNE weitere Fragen
- Setzt Phase automatisch zu "story"
- Speichert Dialog-Score in Datenbank

#### Fehlerbehandlung

| Szenario                      | Verhalten                              |
| ----------------------------- | -------------------------------------- |
| API-Fehler bei continueDialog | ErrorMessage, erneut versuchbar        |
| Fehler bei forceAssessment    | ErrorMessage, aber Dialog wird beendet |
| Network-Fehler                | Retry m√∂glich bis 5 Fragen erreicht    |
| User verl√§sst Seite           | Conversation-History bleibt in State   |

#### Performance

- **Dialog-Phase Dauer:** Typisch 3-5 Minuten (statt unbegrenzt)
- **KI-API-Kosten:** Vorhersehbar (max 5 gpt-4o-mini Calls)
- **User Experience:** Schneller √úbergang zur Story-Phase

---

## üéØ Vereinfachte Score-Berechnung (V1.2 - 2025-10-16)

### Problem gel√∂st

Dialog-Phase konnte vorzeitig durch LLM beendet werden (nach 3-4 statt 5 Fragen).
User f√ºhlten sich ungerecht bewertet, da Dialog-Score (20%) ihren Gesamt-Score senkte, obwohl das LLM die Entscheidung zum vorzeitigen Abbruch traf.

### L√∂sung: Nur Quiz-Score z√§hlt

#### Score-Berechnung

**ALT:**
```
total_score = (dialog_score √ó 0.2) + (story_score √ó 0.2) + (quiz_score √ó 0.6)
```

**NEU:**
```
total_score = quiz_score
```

#### Begr√ºndung

- **Objektivit√§t**: Quiz-Ergebnisse sind eindeutig messbar (richtig/falsch)
- **User-Kontrolle**: User beantwortet ALLE Quiz-Fragen selbst
- **Keine LLM-Willk√ºr**: Dialog-Abbruch beeinflusst Score nicht mehr
- **Transparenz**: "5 von 5 richtig = 100%" ist sofort verst√§ndlich

#### Dialog & Story bleiben wertvoll

- **Dialog**: Ermittelt Vorwissen ‚Üí Personalisiert Schwierigkeitsgrad
- **Story**: Kontextualisiert Lernstoff ‚Üí Besseres Verst√§ndnis
- **Quiz**: Einzige score-relevante Phase ‚Üí Fair & transparent

#### UI-√Ñnderungen

**Completion-Screen:**
- Quiz-Score prominent als Haupt-Score angezeigt
- Dialog als "Bonus-Info" mit ged√§mpftem Styling
- Klartext: "Dies ist dein finaler Score!"

**Dashboard-Cards:**
- Fokus auf Quiz-Score (gro√üe Schrift, prominente Farbe)
- Dialog optional sichtbar als kleiner Badge
- Progress-Bar zeigt Quiz-Performance (Gradient von Purple zu Teal)

#### Implementation

**Datenbank-Migration:** `20251016232329_simplify_score_calculation.sql`
- Trigger-Funktion `update_lesson_total_score()` vereinfacht
- Alle bestehenden Scores automatisch neu berechnet
- Backward-compatible (keine Breaking Changes)

**Ge√§nderte Dateien:**
- `supabase/migrations/20251016232329_simplify_score_calculation.sql` (NEU)
- `components/learning/completion-screen.tsx` (UI-Redesign)
- `components/dashboard/lesson-card.tsx` (UI-Vereinfachung)
- `lib/score.types.ts` (Kommentare angepasst)
- `INTERACTIVE-LEARNING.md` (Diese Dokumentation)

#### Verifikation

‚úÖ Migration erfolgreich durchgef√ºhrt
‚úÖ Trigger aktiv und funktioniert
‚úÖ UI-Komponenten angepasst
‚úÖ Dokumentation aktualisiert

---
