"use server";

/**
 * Voice Dialog Server Actions
 * STT ‚Üí LLM ‚Üí TTS Pipeline f√ºr Voice-basierte Dialog-Phase
 */

import { openai } from "@ai-sdk/openai";
import { generateObject } from "ai";
import { z } from "zod";
import OpenAI from "openai";
import { createServiceClient } from "@/lib/supabase/server";
import { auth } from "@/lib/auth";
import { headers } from "next/headers";
import { redirect } from "next/navigation";
import {
  updateDialogScore,
  updatePhase,
  getResearchData,
  saveDialogMetadata,
  invalidateLessonCache,
  clearDialogHistory,
} from "./database-helpers";
import { generateSpeechAudio } from "./actions-tts";
import type { ResearchData } from "@/lib/lesson.types";

// ============================================
// TYPES
// ============================================

export interface ConversationEntry {
  role: "user" | "assistant";
  content: string; // F√ºr Kompatibilit√§t mit score.types.ts
  text: string; // F√ºr Voice-spezifische Verwendung
  audioUrl?: string; // Nur f√ºr AI-Responses
  timestamp: string;
}

export interface VoiceDialogResult {
  userTranscript: string;
  aiResponse: string;
  aiAudioUrl: string;
  shouldAssess: boolean;
}

export interface VoiceAssessmentResult {
  summary: string;
  audioUrl: string;
  knowledgeLevel: "beginner" | "intermediate" | "advanced";
  confidence: number;
  reasoning: string;
}

// ============================================
// MAIN VOICE PROCESSING PIPELINE
// ============================================

/**
 * Hauptfunktion: Verarbeitet Voice-Input durch STT ‚Üí LLM ‚Üí TTS Pipeline
 */
export async function processVoiceInput(
  lessonId: string,
  userId: string,
  // Now expect a transcript and metadata instead of raw audio
  transcript: string,
  confidence: number | undefined,
  conversationHistory: ConversationEntry[],
  topic: string,
  currentAnswerCount: number
): Promise<VoiceDialogResult> {
  try {
    console.log(
      `üé§ Processing voice transcript for lesson ${lessonId}, answer ${currentAnswerCount}/5`
    );

    // Step 0: Lade User-Pr√§ferenzen
    const session = await auth.api.getSession({ headers: await headers() });
    const userVoice = session?.user?.ttsVoice || "nova";
    console.log(`üéôÔ∏è Using voice preference: ${userVoice}`);

    // Validate transcript with Zod
    const transcriptSchema = z.string().max(32768).min(1);
    const userTranscript = transcriptSchema.parse(transcript);
    console.log(`üìù Transcript received (${userTranscript.length} chars)`);

    const aiResponse = await processDialogResponse(
      lessonId,
      userId,
      userTranscript,
      conversationHistory,
      topic,
      currentAnswerCount
    );

    // Step 2: Text-to-Speech mit User-Pr√§ferenz
    const { audioUrl: aiAudioUrl } = await generateSpeechAudio(
      aiResponse,
      "de",
      userVoice
    );

    // Step 3: Determine if assessment is needed
    const shouldAssess = currentAnswerCount >= 5;

    console.log(`‚úÖ Voice processing complete. Should assess: ${shouldAssess}`);

    return {
      userTranscript,
      aiResponse,
      aiAudioUrl,
      shouldAssess,
    };
  } catch (error) {
    console.error("‚ùå Voice processing failed:", error);
    throw new Error(
      "Sprachverarbeitung fehlgeschlagen. Bitte versuche es erneut."
    );
  }
}

// ============================================
// SPEECH-TO-TEXT (WHISPER)
// ============================================

/**
 * Transkribiert Audio-Blob zu Text mit OpenAI Whisper API
 */
async function transcribeAudio(audioBlob: Blob): Promise<string> {
  try {
    // Convert Blob to Buffer
    const arrayBuffer = await audioBlob.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    // OpenAI Whisper API Call
    const openaiClient = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    const transcription = await openaiClient.audio.transcriptions.create({
      file: new File([buffer], "audio.webm", { type: "audio/webm" }),
      model: "whisper-1",
      language: "de", // Deutsch
      response_format: "text",
    });

    console.log(`üéØ Whisper transcription: "${transcription}"`);
    return transcription as string;
  } catch (error) {
    console.error("‚ùå Whisper transcription failed:", error);
    throw new Error(
      "Spracherkennung fehlgeschlagen. Bitte versuche es erneut."
    );
  }
}

// ============================================
// DIALOG PROCESSING (LLM)
// ============================================

/**
 * Verarbeitet Dialog-Response mit LLM (ohne streamUI)
 * Reuse der bestehenden continueDialog() Logik
 */
async function processDialogResponse(
  lessonId: string,
  userId: string,
  userMessage: string,
  conversationHistory: ConversationEntry[],
  topic: string,
  currentAnswerCount: number
): Promise<string> {
  const dialogModel = process.env.OPENAI_SELECTION_MODEL || "gpt-4o-mini";
  const answerNum = currentAnswerCount;
  const maxAns = 5;

  // ‚úÖ Lade User-Profil f√ºr Personalisierung
  const session = await auth.api.getSession({ headers: await headers() });
  const userProfile = session?.user;

  const userAge = userProfile?.age;
  const userLanguage = userProfile?.language || "de";
  const userExperience = userProfile?.experienceLevel || "beginner";

  // ‚úÖ Personalisierter Context
  const personalizedContext = `
USER-PROFIL (Personalisierung):
${userAge ? `- Alter: ${userAge} Jahre` : "- Alter: Nicht angegeben"}
${
  userExperience
    ? `- Erfahrungslevel: ${userExperience} (passe Komplexit√§t der Fragen an!)`
    : ""
}
${
  userLanguage !== "de"
    ? `- Bevorzugte Sprache: ${userLanguage} (aber Dialog ist auf Deutsch)`
    : ""
}

WICHTIG: Passe deine Fragen an Alter und Erfahrungslevel an!
${userAge && userAge < 14 ? "- Nutze einfache, kindgerechte Sprache" : ""}
${
  userAge && userAge >= 18
    ? "- Nutze anspruchsvolle, professionelle Sprache"
    : ""
}
${
  userExperience === "beginner"
    ? "- Stelle grundlegende Fragen, erkl√§re Konzepte einfach"
    : ""
}
${
  userExperience === "advanced"
    ? "- Stelle tiefergehende Fragen, nutze Fachbegriffe"
    : ""
}
`;

  // ‚úÖ Trigger Background Story-Generierung nach 1. User-Antwort
  if (answerNum === 1) {
    try {
      fetch(
        `${
          process.env.NEXT_PUBLIC_BETTER_AUTH_URL || "http://localhost:3000"
        }/api/generate-story-background`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            lessonId,
            userId,
            topic,
          }),
        }
      ).catch((err) => {
        console.error("‚ö†Ô∏è Failed to trigger background story generation:", err);
      });
      console.log(
        "‚úÖ Background story generation triggered for lesson:",
        lessonId
      );
    } catch (error) {
      console.error("‚ö†Ô∏è Exception while triggering background story:", error);
    }
  }

  // Convert conversation history to LLM format
  const messages = conversationHistory.map((entry) => ({
    role: entry.role,
    content: entry.text,
  }));

  // Add current user message
  messages.push({ role: "user" as const, content: userMessage });

  // Generate response with OpenAI
  const openaiClient = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  });

  const response = await openaiClient.chat.completions.create({
    model: dialogModel,
    messages: [
      {
        role: "system",
        content: `Du bist ein freundlicher Lern-Coach f√ºr das Thema "${topic}".

${personalizedContext}

AUFGABE:
- Stelle gezielte Fragen, um das Vorwissen des Nutzers zu ermitteln
- Passe deine Fragen dynamisch an die Antworten an
- Sei motivierend und unterst√ºtzend
- Duze den Nutzer IMMER (verwende "du", "dein", "dir")

STRIKTE REGEL - EXAKT 5 FRAGEN:
- Der Nutzer hat bisher ${answerNum} von ${maxAns} Fragen beantwortet (erste Frage bereits gestellt)
- Du MUSST noch ${maxAns - answerNum} weitere Frage(n) stellen
- EINE pr√§gnante Frage pro Message (1-2 S√§tze)
- Keine Multiple-Choice, sondern offene Fragen
- Baue auf vorherigen Antworten auf

WICHTIG: Keine Zusammenfassungen, keine Bewertungen - nur Fragen stellen!
WICHTIG: IMMER "Du" verwenden, niemals "Sie"!`,
      },
      ...messages,
    ],
    max_tokens: 200,
    temperature: 0.7,
  });

  const aiResponse =
    response.choices[0]?.message?.content ||
    "Entschuldigung, ich konnte keine Antwort generieren.";
  console.log(`ü§ñ LLM Response: "${aiResponse}"`);

  return aiResponse;
}

// ============================================
// VOICE ASSESSMENT (nach 5. Frage)
// ============================================

/**
 * Force Assessment nach 5. Voice-Dialog Antwort
 * Analysiert Conversation, erstellt Assessment, wechselt Phase
 */
export async function forceVoiceAssessment(
  lessonId: string,
  userId: string,
  conversationHistory: ConversationEntry[],
  topic: string
): Promise<VoiceAssessmentResult> {
  try {
    console.log(`üéØ Starting voice assessment for lesson ${lessonId}`);

    // Step 1: LLM Assessment
    const assessment = await generateAssessment(conversationHistory, topic);
    console.log(
      `üìä Assessment: ${assessment.knowledgeLevel} (${assessment.confidence}%)`
    );

    // Step 2: Lade User-Pr√§ferenzen
    const session = await auth.api.getSession({ headers: await headers() });
    const userVoice = session?.user?.ttsVoice || "nova";
    console.log(`üéôÔ∏è Using voice preference for assessment: ${userVoice}`);

    // Step 3: TTS f√ºr Assessment-Summary mit User-Pr√§ferenz
    const summaryText = `Perfekt! Ich habe dein Wissen zu ${topic} analysiert.
Dein Level ist ${assessment.knowledgeLevel} mit ${assessment.confidence}% Konfidenz.
${assessment.reasoning}
Jetzt geht's weiter zur Story-Phase!`;

    const { audioUrl } = await generateSpeechAudio(
      summaryText,
      "de",
      userVoice
    );

    // Step 3: Datenbank-Updates (Parallel f√ºr Performance)
    await Promise.all([
      updateDialogScore(lessonId, userId, assessment.confidence),
      saveDialogMetadata(lessonId, userId, {
        conversationHistory: conversationHistory.map((entry) => ({
          role: entry.role,
          content: entry.content,
        })),
        knowledgeLevel: assessment.knowledgeLevel,
        assessmentReasoning: assessment.reasoning,
        userResponses: conversationHistory
          .filter((entry) => entry.role === "user")
          .map((entry) => entry.text),
      }),
      updatePhase(lessonId, "story"),
    ]);

    // Step 4: Check Story Generation Status
    const storyReady = await checkStoryGenerationStatus(lessonId);
    if (!storyReady) {
      console.warn("‚ö†Ô∏è Story not ready, triggering fallback generation");
      await generateStoryFallback(lessonId, topic);
    }

    // Step 5: Cache Invalidierung + Transaction Delay
    await invalidateLessonCache(lessonId);
    await delay(3000); // 3s f√ºr Supabase Transaction Commit

    // Optional: Clear Dialog History (GDPR)
    await clearDialogHistory(lessonId);

    console.log(`‚úÖ Voice assessment complete for lesson ${lessonId}`);

    return {
      summary: summaryText,
      audioUrl,
      knowledgeLevel: assessment.knowledgeLevel,
      confidence: assessment.confidence,
      reasoning: assessment.reasoning,
    };
  } catch (error) {
    console.error("‚ùå Voice assessment failed:", error);
    throw new Error("Bewertung fehlgeschlagen. Bitte versuche es erneut.");
  }
}

/**
 * Generiert Assessment basierend auf Conversation History
 */
async function generateAssessment(
  conversationHistory: ConversationEntry[],
  topic: string
): Promise<{
  knowledgeLevel: "beginner" | "intermediate" | "advanced";
  confidence: number;
  reasoning: string;
}> {
  const { object } = await generateObject({
    model: openai("gpt-4o-mini"),
    schema: z.object({
      knowledgeLevel: z.enum(["beginner", "intermediate", "advanced"]),
      confidence: z.number().min(0).max(100),
      reasoning: z.string(),
    }),
    prompt: `Analysiere dieses Gespr√§ch zum Thema "${topic}" und bewerte das Wissen:

${conversationHistory
  .map((entry) => `${entry.role === "user" ? "User" : "AI"}: ${entry.text}`)
  .join("\n\n")}

Bewerte basierend auf:
- Tiefe der Antworten
- Verwendung von Fachbegriffen
- Verst√§ndnis von Zusammenh√§ngen
- F√§higkeit, Beispiele zu nennen`,
  });

  return object;
}

// ============================================
// STORY GENERATION HELPERS
// ============================================

/**
 * Pr√ºft ob Background Story-Generierung abgeschlossen ist
 */
async function checkStoryGenerationStatus(lessonId: string): Promise<boolean> {
  const supabase = createServiceClient();

  const { data: flashcards } = await supabase
    .from("flashcard")
    .select("id, phase, learning_content")
    .eq("lesson_id", lessonId)
    .eq("phase", "story");

  // Story ist fertig wenn mind. 3 Story-Flashcards existieren
  return !!(
    flashcards &&
    flashcards.length >= 3 &&
    flashcards.every((card) => card.learning_content?.story?.narrative)
  );
}

/**
 * Fallback: Synchrone Story-Generierung falls Background-Job fehlschlug
 */
async function generateStoryFallback(
  lessonId: string,
  topic: string
): Promise<void> {
  console.log("üö® Fallback: Generating story synchronously");

  try {
    // Nutze bestehende Story-Generation Logik (aus V1.3)
    // Trigger background story generation via API
    const response = await fetch(
      `${
        process.env.NEXT_PUBLIC_BETTER_AUTH_URL || "http://localhost:3000"
      }/api/generate-story-background`,
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          lessonId,
          userId: "system", // Fallback generation
          topic,
        }),
      }
    );

    if (response.ok) {
      console.log("‚úÖ Fallback story generation triggered");
    } else {
      console.warn("‚ö†Ô∏è Fallback story generation failed");
    }
  } catch (error) {
    console.error("‚ùå Fallback story generation failed:", error);
    // Nicht kritisch - Story wird sp√§ter in StoryGeneratorWrapper nachgeholt
  }
}

// ============================================
// UTILITY FUNCTIONS
// ============================================

function delay(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

// ============================================
// ERROR HANDLING
// ============================================

// Error classes moved to lib/voice-dialog-errors.ts
// due to "use server" file restrictions

// ============================================
// INITIAL QUESTION GENERATION (Voice Chat)
// ============================================

/**
 * Generiert initiale Begr√º√üung + erste Fachfrage f√ºr Voice Chat
 * Kombiniert beides in einer Nachricht, um direkt mit fachlicher Frage zu starten
 */
export async function generateInitialQuestion(
  lessonId: string,
  topic: string,
  userId: string
): Promise<string> {
  try {
    console.log(`üéôÔ∏è Generating initial question for topic: ${topic}`);

    const session = await auth.api.getSession({ headers: await headers() });
    const userProfile = session?.user;

    const openaiClient = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

    const response = await openaiClient.chat.completions.create({
      model: process.env.OPENAI_SELECTION_MODEL || "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: `Du bist ein freundlicher Lern-Coach f√ºr das Thema "${topic}".

AUFGABE:
- Erstelle eine kurze Begr√º√üung (1-2 S√§tze)
- Stelle DIREKT die erste fachliche Frage zum Thema
- Kombiniere beides in EINER Nachricht
- Duze den Nutzer IMMER

BEISPIEL:
"Hallo! Ich m√∂chte dein Vorwissen zu ${topic} kennenlernen. Lass uns direkt starten: Was wei√üt du bereits √ºber [Kernkonzept]?"

${
  userProfile?.age && userProfile.age < 14
    ? "- Nutze einfache, kindgerechte Sprache"
    : ""
}
${
  userProfile?.experienceLevel === "beginner"
    ? "- Stelle eine grundlegende Einstiegsfrage"
    : ""
}
${
  userProfile?.experienceLevel === "advanced"
    ? "- Stelle eine anspruchsvollere Frage"
    : ""
}
`,
        },
      ],
      max_tokens: 150,
      temperature: 0.7,
    });

    const questionText =
      response.choices[0]?.message?.content ||
      `Hallo! Ich m√∂chte dein Vorwissen zu ${topic} kennenlernen. Lass uns direkt starten: Was wei√üt du bereits √ºber dieses Thema?`;

    console.log(`‚úÖ Generated initial question: "${questionText}"`);
    return questionText;
  } catch (error) {
    console.error("‚ùå Failed to generate initial question:", error);
    return `Hallo! Ich m√∂chte dein Vorwissen zu ${topic} kennenlernen. Lass uns direkt starten: Was wei√üt du bereits √ºber dieses Thema?`;
  }
}
